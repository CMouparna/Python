{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CMouparna/Python/blob/main/Mouparna_Chattopadhyay_2211550_Assignment_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0L9Xooq-4NC"
      },
      "source": [
        "## Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njElkEgh-4NE"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2 #importing open cv "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc1J7HmU-4NF"
      },
      "source": [
        "###  cv2.imread () method loads an image from the specified file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0vjatfa-4NG"
      },
      "outputs": [],
      "source": [
        "image_c=cv2.imread(\"C:\\\\Users\\\\2211444\\\\Downloads\\\\Trudeau.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mkHWXQF-4NG"
      },
      "source": [
        "### Converting the color image to grayscale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvuP4rrE-4NH"
      },
      "outputs": [],
      "source": [
        "image_g=cv2.cvtColor(image_c,cv2.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zd2EFUBL-4NH"
      },
      "source": [
        " **.imshow** :cv2.imshow() method is used to display an image in a window. \n",
        "\n",
        "**cv2 waikey ()** : waits for the pressed key event before going to the next set of operations. Its syntax is as follows – Syntax cv2.waitKey (delay) It waits for ‘delay’ milliseconds for any positive value of ‘delay’. And for any negative value of ‘delay’ or when ‘delay’ = 0, the function waits infinitely for a key event.\n",
        "**cv2.destroyAllWindows()**:. destroyWindow () only destroys a specific window but in the case of destroyAllWindow () it destroys all windows.\n",
        "\n",
        "\n",
        "#### Displaying the image in color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYcrBG6K-4NQ"
      },
      "outputs": [],
      "source": [
        "cv2.imshow('Trudeau in Color',image_c) \n",
        "cv2.waitKey()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUkVGzdI-4NR"
      },
      "source": [
        "#### Displaying the image in greyscale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqXGUvm9-4NR"
      },
      "outputs": [],
      "source": [
        "cv2.imshow('Trudeau in Grey',image_g)\n",
        "cv2.waitKey()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA3oNYpx-4NR"
      },
      "source": [
        "\n",
        "Object Detection using Haar feature-based cascade classifiers is an effective object detection method proposed by Paul Viola and Michael Jones in their paper, \"Rapid Object Detection using a Boosted Cascade of Simple Features\" in 2001. It is a machine learning based approach where a cascade function is trained from a lot of positive and negative images. It is then used to detect objects in other images. (reference: https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html)\n",
        "\n",
        "\n",
        "OpenCV provides a training method (see Cascade Classifier Training) or pretrained models, that can be read using the cv::CascadeClassifier::load method.\n",
        "a cv::CascadeClassifier is created and the necessary XML file is loaded using the cv::CascadeClassifier::load method. Afterwards, the detection is done using the **cv::CascadeClassifier::detectMultiScale** method, which returns boundary rectangles for the detected faces or eyes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRoKUsaX-4NS"
      },
      "outputs": [],
      "source": [
        "face_detection=cv2.CascadeClassifier(\"C:\\\\Users\\\\2211444\\\\Desktop\\\\face detection\\\\haarcascade_frontalface_default.xml\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YQsRgFJ-4NT"
      },
      "source": [
        "The parameters .detectMultiScake takes are  read_img, scale factor , minNeihbours \n",
        "\n",
        "\n",
        "**read_img**: Image to be read\n",
        "**scaleFactor**:  it specifies how much the image size is reduced with each scale.\n",
        "**MinNeighbours**: specifies how many neighbors each candidate rectangle should have to retain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXlf4E8W-4NT"
      },
      "outputs": [],
      "source": [
        "faces=face_detection.detectMultiScale(image_c,1.1,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eexxHFc8-4NT",
        "outputId": "1362e5d7-1690-4ddc-99af-3b8b8f6013c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 4)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "faces.shape #checking the shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBfeOb1Z-4NU"
      },
      "source": [
        " If faces are found, it returns the positions of detected faces as Rect(x,y,w,h). Once we get these locations, we can create a ROI for the face and apply eye detection on this ROI (since eyes are always on the face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgTSOpWB-4NU",
        "outputId": "a2df60ce-d17a-4872-a166-ed59803ebdee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[332, 121, 208, 208]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "faces #this is the coordinate for the area where it found the face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmyI1TIP-4NV",
        "outputId": "5cc8f9a3-989c-4d11-8cce-ab3efeabc638"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([121])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "faces[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CiPcxA--4NV"
      },
      "source": [
        "x,y are pixel location of faces, w,h are width and height of faces. \n",
        "**cv2.rectangle()** function used for draw rectangle over the detected object, image_c is input image, (x,y),(x+w, y+h) are locations of rectangle,(0,255,255) is color of a rectangle this argument gets passed as a tuple for BGR,we would use (0,0,255) for red, 3 is thickness of rectangle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3n-RFrgJ-4NV"
      },
      "outputs": [],
      "source": [
        "x=int(faces[:,0])\n",
        "y=int(faces[:,1])\n",
        "w=int(faces[:,2])\n",
        "h=int(faces[:,3])\n",
        "\n",
        "cv2.rectangle(image_c,(x,y),(x+w,y+h),(0,255,255),3)\n",
        "cv2.imshow(\"Single  Face Detection\",image_c)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTifsJeG-4NW"
      },
      "source": [
        "## Detecting Multiple faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4ngoxy1-4NW"
      },
      "outputs": [],
      "source": [
        "image_c=cv2.imread(\"C:\\\\Users\\\\2211444\\\\Desktop\\\\face detection\\\\Scientist.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk88vSz2-4NW"
      },
      "outputs": [],
      "source": [
        "image_g=cv2.cvtColor(image_c,cv2.COLOR_BGR2GRAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4JRkcxY-4NW"
      },
      "outputs": [],
      "source": [
        "cv2.imshow('Scientist in Color',image_c)\n",
        "cv2.waitKey()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLqqbShe-4NX"
      },
      "outputs": [],
      "source": [
        "cv2.imshow('Scientist in greyscale',image_g)\n",
        "cv2.waitKey()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krhxuq9E-4NX"
      },
      "outputs": [],
      "source": [
        "face_detection=cv2.CascadeClassifier(\"C:\\\\Users\\\\2211444\\\\Desktop\\\\face detection\\\\haarcascade_frontalface_default.xml\")\n",
        "faces=face_detection.detectMultiScale(image_c,1.1,5)\n",
        "for (x,y,w,h) in faces:\n",
        "    cv2.rectangle(image_c,(x,y),(x+w,y+h),(255,0,255),10)\n",
        "    cv2.imshow('Single face Detection',image_c)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGNBwe8c-4NX"
      },
      "source": [
        "## Detect eyes and faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oS658If1-4NX"
      },
      "outputs": [],
      "source": [
        "image_c=cv2.imread(\"C:\\\\Users\\\\2211444\\\\Downloads\\\\Trudeau.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9FepFnU-4NY"
      },
      "outputs": [],
      "source": [
        "face_classifier=cv2.CascadeClassifier(\"C:\\\\Users\\\\2211444\\\\Desktop\\\\face detection\\\\haarcascade_frontalface_default.xml\")\n",
        "eye_classifier=cv2.CascadeClassifier(\"C:\\\\Users\\\\2211444\\\\Desktop\\\\face detection\\\\haarcascade_eye.xml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcsCswQX-4NY"
      },
      "outputs": [],
      "source": [
        "faces = face_classifier.detectMultiScale(image_c, 1.2, 5)\n",
        " \n",
        "for (x,y,w,h) in faces:\n",
        "    cv2.rectangle(image_c,(x,y),(x+w,y+h),(0,255,255), 3)\n",
        "    cv2.imshow('Trudeau Face and Eyes',image_c)\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "    # Select the face\n",
        "    face_region = image_c[y:y+h, x:x+w]\n",
        "\n",
        "    eyes = eye_classifier.detectMultiScale(face_region)\n",
        "\n",
        "    for (eyes_x, eyes_y, eyes_w,eyes_h) in eyes:\n",
        "        cv2.rectangle(face_region,(eyes_x, eyes_y),(eyes_x + eyes_w, eyes_y + eyes_h), (0,255,0),3)\n",
        "        cv2.imshow('Trudeau Face and Eyes',image_c)\n",
        "        cv2.waitKey(0)\n",
        "\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jireS1M-4NY"
      },
      "outputs": [],
      "source": [
        "cv2.imshow('Face Region',image_c[y:y+h,x:x+w])\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMU0yhCH-4NY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}